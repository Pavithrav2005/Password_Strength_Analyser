{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5b28fc",
   "metadata": {},
   "source": [
    "# üîê Password Strength Analyzer with Adversarial Training\n",
    "\n",
    "## Educational Tutorial and Implementation Guide\n",
    "\n",
    "Welcome to this comprehensive tutorial on building an advanced password strength analyzer using machine learning and adversarial training techniques. This notebook will guide you through the entire process of creating a robust password security assessment system.\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will understand:\n",
    "\n",
    "1. **Feature Engineering for Password Analysis**: How to extract meaningful features from password strings\n",
    "2. **Machine Learning for Security**: Applying ML techniques to cybersecurity problems\n",
    "3. **Adversarial Training**: Making models robust against deceptive inputs\n",
    "4. **Real-world Application**: Building production-ready security tools\n",
    "\n",
    "### üß† Problem Statement\n",
    "\n",
    "Traditional password strength checkers rely on simple rules (length, character types) that can be easily fooled. For example:\n",
    "- `P@ssw0rd123!` looks strong but is based on a common weak password\n",
    "- `qwerty2024!` contains predictable patterns despite having symbols and numbers\n",
    "\n",
    "Our goal is to build an ML model that:\n",
    "- Learns from real password breach data\n",
    "- Recognizes subtle weakness patterns\n",
    "- Resists adversarial \"strengthening\" tricks\n",
    "- Provides actionable security feedback\n",
    "\n",
    "### üìä Dataset Structure\n",
    "\n",
    "We'll work with password datasets containing:\n",
    "```\n",
    "Password         | Crack_Time_Sec | Strength_Label\n",
    "123456          | 0.001          | Weak\n",
    "qW3@Zx9!        | 1223           | Strong  \n",
    "password1       | 0.02           | Weak\n",
    "G0ldfishKing!   | 4000           | Strong\n",
    "```\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b4e7f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Let's start by importing all the necessary libraries for our password strength analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d355121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Text analysis libraries\n",
    "import textstat\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "\n",
    "# Utility libraries\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "import time\n",
    "from faker import Faker\n",
    "\n",
    "# Add src directory to path for our custom modules\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Our custom modules\n",
    "from feature_extraction import PasswordFeatureExtractor, extract_features_batch\n",
    "from data_generator import PasswordDataGenerator, create_sample_dataset\n",
    "from adversarial_training import AdversarialPasswordGenerator\n",
    "from model_training import PasswordStrengthModel\n",
    "\n",
    "# Configure display options\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c922798",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Password Dataset\n",
    "\n",
    "In this section, we'll generate a synthetic password dataset that mimics real-world password patterns. In a production environment, you would use actual breach datasets like RockYou.txt or HaveIBeenPwned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a comprehensive password dataset\n",
    "print(\"üîÑ Generating password dataset...\")\n",
    "dataset = create_sample_dataset()\n",
    "\n",
    "print(f\"‚úÖ Generated {len(dataset)} password samples\")\n",
    "print(f\"\\nDataset shape: {dataset.shape}\")\n",
    "print(f\"Columns: {list(dataset.columns)}\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\nüìä Dataset Overview:\")\n",
    "print(dataset.head(10))\n",
    "\n",
    "print(\"\\nüìà Strength Label Distribution:\")\n",
    "strength_counts = dataset['Strength_Label'].value_counts()\n",
    "print(strength_counts)\n",
    "\n",
    "# Visualize the distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Strength distribution\n",
    "strength_counts.plot(kind='bar', ax=ax1, color=['red', 'orange', 'green'])\n",
    "ax1.set_title('Password Strength Distribution')\n",
    "ax1.set_xlabel('Strength Level')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Crack time distribution (log scale)\n",
    "dataset['log_crack_time'] = np.log10(dataset['Crack_Time_Sec'] + 1)\n",
    "ax2.hist(dataset['log_crack_time'], bins=50, alpha=0.7, color='skyblue')\n",
    "ax2.set_title('Distribution of Crack Times (Log Scale)')\n",
    "ax2.set_xlabel('Log10(Crack Time Seconds)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show some example passwords by strength\n",
    "print(\"\\nüîç Example Passwords by Strength:\")\n",
    "for strength in ['Weak', 'Medium', 'Strong']:\n",
    "    examples = dataset[dataset['Strength_Label'] == strength]['Password'].head(5).tolist()\n",
    "    print(f\"\\n{strength} passwords:\")\n",
    "    for i, pwd in enumerate(examples, 1):\n",
    "        print(f\"  {i}. {pwd}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"Average password length: {dataset['Password'].str.len().mean():.2f}\")\n",
    "print(f\"Min crack time: {dataset['Crack_Time_Sec'].min():.3f} seconds\")\n",
    "print(f\"Max crack time: {dataset['Crack_Time_Sec'].max():.0f} seconds\")\n",
    "print(f\"Median crack time: {dataset['Crack_Time_Sec'].median():.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0c9e8",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering: Password Analysis\n",
    "\n",
    "Feature engineering is crucial for password strength analysis. We'll extract various features that capture different aspects of password security, from basic composition to complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the feature extractor\n",
    "feature_extractor = PasswordFeatureExtractor()\n",
    "\n",
    "# Extract features for a sample password to understand the feature set\n",
    "sample_password = \"MyP@ssw0rd123!\"\n",
    "sample_features = feature_extractor.extract_features(sample_password)\n",
    "\n",
    "print(f\"üîç Feature Analysis for password: '{sample_password}'\")\n",
    "print(f\"Total features extracted: {len(sample_features)}\")\n",
    "print(\"\\nüìä Feature breakdown:\")\n",
    "\n",
    "# Group features by category for better understanding\n",
    "feature_categories = {\n",
    "    'Basic Composition': ['length', 'uppercase_count', 'lowercase_count', 'digit_count', 'symbol_count'],\n",
    "    'Character Ratios': ['uppercase_ratio', 'lowercase_ratio', 'digit_ratio', 'symbol_ratio'],\n",
    "    'Diversity Metrics': ['char_set_size', 'unique_char_ratio', 'entropy'],\n",
    "    'Pattern Detection': ['has_keyboard_pattern', 'keyboard_pattern_length', 'has_sequential_chars', \n",
    "                         'sequential_char_count', 'has_repeated_chars', 'repeated_char_count'],\n",
    "    'Security Analysis': ['substitution_count', 'contains_dictionary_word', 'contains_date', \n",
    "                         'contains_year', 'complexity_score']\n",
    "}\n",
    "\n",
    "for category, features in feature_categories.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for feature in features:\n",
    "        if feature in sample_features:\n",
    "            value = sample_features[feature]\n",
    "            print(f\"  {feature}: {value}\")\n",
    "\n",
    "# Extract features for the entire dataset\n",
    "print(f\"\\nüîÑ Extracting features for {len(dataset)} passwords...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Extract features for all passwords\n",
    "feature_list = extract_features_batch(dataset['Password'].tolist())\n",
    "features_df = pd.DataFrame(feature_list)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"‚úÖ Feature extraction completed in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Feature matrix shape: {features_df.shape}\")\n",
    "\n",
    "# Display feature correlation heatmap\n",
    "plt.figure(figsize=(15, 12))\n",
    "correlation_matrix = features_df.corr()\n",
    "\n",
    "# Select most important features for visualization\n",
    "important_features = [\n",
    "    'length', 'entropy', 'complexity_score', 'unique_char_ratio',\n",
    "    'uppercase_ratio', 'digit_ratio', 'symbol_ratio',\n",
    "    'has_keyboard_pattern', 'has_sequential_chars', 'has_repeated_chars',\n",
    "    'contains_dictionary_word', 'substitution_count'\n",
    "]\n",
    "\n",
    "# Filter correlation matrix to important features\n",
    "filtered_corr = correlation_matrix.loc[important_features, important_features]\n",
    "\n",
    "sns.heatmap(filtered_corr, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Feature Correlation Matrix (Key Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature statistics by strength level\n",
    "print(\"\\nüìà Feature Statistics by Strength Level:\")\n",
    "features_with_labels = features_df.copy()\n",
    "features_with_labels['Strength_Label'] = dataset['Strength_Label']\n",
    "\n",
    "feature_stats = features_with_labels.groupby('Strength_Label')[important_features].mean()\n",
    "print(feature_stats.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20db585",
   "metadata": {},
   "source": [
    "## 4. Password Entropy and Pattern Detection\n",
    "\n",
    "Entropy is a crucial measure of password unpredictability. Let's dive deeper into entropy calculation and pattern detection techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze entropy and patterns for different types of passwords\n",
    "test_passwords = [\n",
    "    \"123456\",           # Very weak - sequential numbers\n",
    "    \"password\",         # Weak - dictionary word\n",
    "    \"qwerty123\",        # Weak - keyboard pattern + numbers\n",
    "    \"P@ssw0rd123!\",     # Deceptively strong - common substitutions\n",
    "    \"MySecure2024!\",    # Medium - predictable year\n",
    "    \"7$kL9#mN2@pQ5\",    # Strong - truly random\n",
    "    \"correcthorsebatterystaple\",  # Strong - passphrase\n",
    "]\n",
    "\n",
    "print(\"üîç Detailed Analysis of Different Password Types:\\n\")\n",
    "\n",
    "for password in test_passwords:\n",
    "    features = feature_extractor.extract_features(password)\n",
    "    \n",
    "    print(f\"Password: '{password}'\")\n",
    "    print(f\"  Length: {features['length']}\")\n",
    "    print(f\"  Entropy: {features['entropy']:.3f} bits\")\n",
    "    print(f\"  Character set size: {features['char_set_size']}\")\n",
    "    print(f\"  Unique char ratio: {features['unique_char_ratio']:.3f}\")\n",
    "    print(f\"  Complexity score: {features['complexity_score']}\")\n",
    "    \n",
    "    # Pattern detection\n",
    "    patterns = []\n",
    "    if features['has_keyboard_pattern']:\n",
    "        patterns.append(\"Keyboard pattern\")\n",
    "    if features['has_sequential_chars']:\n",
    "        patterns.append(\"Sequential characters\")\n",
    "    if features['has_repeated_chars']:\n",
    "        patterns.append(\"Repeated characters\")\n",
    "    if features['contains_dictionary_word']:\n",
    "        patterns.append(\"Dictionary word\")\n",
    "    if features['has_common_substitutions']:\n",
    "        patterns.append(\"Common substitutions\")\n",
    "    if features['contains_year']:\n",
    "        patterns.append(\"Contains year\")\n",
    "    \n",
    "    if patterns:\n",
    "        print(f\"  Detected patterns: {', '.join(patterns)}\")\n",
    "    else:\n",
    "        print(f\"  Detected patterns: None\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Visualize entropy distribution by strength\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Entropy by strength\n",
    "features_with_labels['entropy'].hist(by=features_with_labels['Strength_Label'], \n",
    "                                    ax=axes[0,0], bins=30, alpha=0.7)\n",
    "axes[0,0].set_title('Entropy Distribution by Strength')\n",
    "axes[0,0].set_xlabel('Entropy (bits)')\n",
    "\n",
    "# Length by strength\n",
    "features_with_labels['length'].hist(by=features_with_labels['Strength_Label'], \n",
    "                                   ax=axes[0,1], bins=20, alpha=0.7)\n",
    "axes[0,1].set_title('Length Distribution by Strength')\n",
    "axes[0,1].set_xlabel('Password Length')\n",
    "\n",
    "# Complexity score by strength\n",
    "features_with_labels['complexity_score'].hist(by=features_with_labels['Strength_Label'], \n",
    "                                             ax=axes[1,0], bins=30, alpha=0.7)\n",
    "axes[1,0].set_title('Complexity Score Distribution by Strength')\n",
    "axes[1,0].set_xlabel('Complexity Score')\n",
    "\n",
    "# Character diversity by strength\n",
    "features_with_labels['unique_char_ratio'].hist(by=features_with_labels['Strength_Label'], \n",
    "                                              ax=axes[1,1], bins=20, alpha=0.7)\n",
    "axes[1,1].set_title('Character Diversity by Strength')\n",
    "axes[1,1].set_xlabel('Unique Character Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pattern prevalence analysis\n",
    "pattern_features = ['has_keyboard_pattern', 'has_sequential_chars', 'has_repeated_chars', \n",
    "                   'contains_dictionary_word', 'has_common_substitutions', 'contains_year']\n",
    "\n",
    "pattern_stats = []\n",
    "for strength in ['Weak', 'Medium', 'Strong']:\n",
    "    strength_data = features_with_labels[features_with_labels['Strength_Label'] == strength]\n",
    "    row = {'Strength': strength}\n",
    "    for pattern in pattern_features:\n",
    "        prevalence = strength_data[pattern].mean() * 100\n",
    "        row[pattern.replace('has_', '').replace('contains_', '').replace('_', ' ').title()] = f\"{prevalence:.1f}%\"\n",
    "    pattern_stats.append(row)\n",
    "\n",
    "pattern_df = pd.DataFrame(pattern_stats)\n",
    "print(\"üìä Pattern Prevalence by Strength Level:\")\n",
    "print(pattern_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0e615",
   "metadata": {},
   "source": [
    "## 5. Encode Target Variables\n",
    "\n",
    "We'll prepare our target variables for both classification (strength labels) and regression (crack time) approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba201c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variables\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Classification target: Strength labels (Weak=0, Medium=1, Strong=2)\n",
    "y_classification = label_encoder.fit_transform(dataset['Strength_Label'])\n",
    "\n",
    "# Regression target: Log-transformed crack time (for better distribution)\n",
    "y_regression = np.log10(dataset['Crack_Time_Sec'] + 1)\n",
    "\n",
    "print(\"üéØ Target Variable Encoding:\")\n",
    "print(f\"Classification labels: {label_encoder.classes_}\")\n",
    "print(f\"Label encoding: {dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))}\")\n",
    "\n",
    "print(f\"\\nClassification target distribution:\")\n",
    "unique, counts = np.unique(y_classification, return_counts=True)\n",
    "for label, count in zip(label_encoder.classes_, counts):\n",
    "    print(f\"  {label}: {count} ({count/len(y_classification)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nRegression target (log crack time) statistics:\")\n",
    "print(f\"  Mean: {y_regression.mean():.3f}\")\n",
    "print(f\"  Std: {y_regression.std():.3f}\")\n",
    "print(f\"  Min: {y_regression.min():.3f}\")\n",
    "print(f\"  Max: {y_regression.max():.3f}\")\n",
    "\n",
    "# Visualize target distributions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Classification target\n",
    "pd.Series(y_classification).value_counts().sort_index().plot(kind='bar', ax=ax1, \n",
    "                                                            color=['red', 'orange', 'green'])\n",
    "ax1.set_title('Classification Target Distribution')\n",
    "ax1.set_xlabel('Strength Level (0=Weak, 1=Medium, 2=Strong)')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Regression target\n",
    "ax2.hist(y_regression, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax2.set_title('Regression Target Distribution (Log Crack Time)')\n",
    "ax2.set_xlabel('Log10(Crack Time + 1)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Prepare feature matrix X\n",
    "X = features_df.copy()\n",
    "\n",
    "print(f\"\\nüìä Final dataset shapes:\")\n",
    "print(f\"  Features (X): {X.shape}\")\n",
    "print(f\"  Classification target (y_classification): {y_classification.shape}\")\n",
    "print(f\"  Regression target (y_regression): {y_regression.shape}\")\n",
    "\n",
    "# Check for any missing values\n",
    "missing_features = X.isnull().sum().sum()\n",
    "print(f\"\\nüîç Data quality check:\")\n",
    "print(f\"  Missing feature values: {missing_features}\")\n",
    "print(f\"  Feature data types: {X.dtypes.value_counts().to_dict()}\")\n",
    "\n",
    "if missing_features > 0:\n",
    "    print(\"  Filling missing values with 0...\")\n",
    "    X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0eca68",
   "metadata": {},
   "source": [
    "## 6. Split Data into Train and Test Sets\n",
    "\n",
    "We'll create training and testing datasets with stratified sampling to ensure balanced representation across strength levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe33f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for classification and regression tasks\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    X, y_classification, test_size=0.2, random_state=42, stratify=y_classification\n",
    ")\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_regression, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"üìä Dataset Split Summary:\")\n",
    "print(f\"Classification task:\")\n",
    "print(f\"  Training set: {X_train_cls.shape[0]} samples\")\n",
    "print(f\"  Test set: {X_test_cls.shape[0]} samples\")\n",
    "print(f\"  Features: {X_train_cls.shape[1]}\")\n",
    "\n",
    "print(f\"\\nRegression task:\")\n",
    "print(f\"  Training set: {X_train_reg.shape[0]} samples\")\n",
    "print(f\"  Test set: {X_test_reg.shape[0]} samples\")\n",
    "\n",
    "# Check stratification worked correctly\n",
    "print(f\"\\nüéØ Class distribution in training set:\")\n",
    "train_dist = pd.Series(y_train_cls).value_counts().sort_index()\n",
    "for i, (label, count) in enumerate(zip(label_encoder.classes_, train_dist)):\n",
    "    percentage = count / len(y_train_cls) * 100\n",
    "    print(f\"  {label}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüéØ Class distribution in test set:\")\n",
    "test_dist = pd.Series(y_test_cls).value_counts().sort_index()\n",
    "for i, (label, count) in enumerate(zip(label_encoder.classes_, test_dist)):\n",
    "    percentage = count / len(y_test_cls) * 100\n",
    "    print(f\"  {label}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize the split\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Training set distribution\n",
    "train_dist.plot(kind='bar', ax=axes[0], color=['red', 'orange', 'green'], alpha=0.7)\n",
    "axes[0].set_title('Training Set - Strength Distribution')\n",
    "axes[0].set_xlabel('Strength Level')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Test set distribution\n",
    "test_dist.plot(kind='bar', ax=axes[1], color=['red', 'orange', 'green'], alpha=0.7)\n",
    "axes[1].set_title('Test Set - Strength Distribution')\n",
    "axes[1].set_xlabel('Strength Level')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Data split completed successfully with proper stratification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b399ce",
   "metadata": {},
   "source": [
    "## 7. Train Random Forest and XGBoost Models\n",
    "\n",
    "Let's train both Random Forest and XGBoost models to compare their performance on password strength prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7b8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='mlogloss'\n",
    "    )\n",
    "}\n",
    "\n",
    "# Store results\n",
    "model_results = {}\n",
    "\n",
    "print(\"üöÄ Training Models...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Training {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_cls, y_train_cls)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train_cls)\n",
    "    y_pred_test = model.predict(X_test_cls)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train_cls, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test_cls, y_pred_test)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_cls, y_train_cls, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Store results\n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'training_time': training_time,\n",
    "        'y_pred_test': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {name} Training Complete!\")\n",
    "    print(f\"   Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"   Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"   CV Accuracy: {cv_scores.mean():.4f} (¬±{cv_scores.std()*2:.4f})\")\n",
    "    print(f\"   Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Compare model performance\n",
    "print(f\"\\nüìä Model Comparison Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "comparison_data = []\n",
    "for name, results in model_results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': f\"{results['test_accuracy']:.4f}\",\n",
    "        'CV Accuracy': f\"{results['cv_mean']:.4f} ¬± {results['cv_std']*2:.4f}\",\n",
    "        'Training Time': f\"{results['training_time']:.2f}s\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "models_list = list(model_results.keys())\n",
    "test_accuracies = [model_results[model]['test_accuracy'] for model in models_list]\n",
    "cv_accuracies = [model_results[model]['cv_mean'] for model in models_list]\n",
    "\n",
    "x = np.arange(len(models_list))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, test_accuracies, width, label='Test Accuracy', alpha=0.8)\n",
    "axes[0].bar(x + width/2, cv_accuracies, width, label='CV Accuracy', alpha=0.8)\n",
    "axes[0].set_xlabel('Models')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Model Performance Comparison')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models_list, rotation=45)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim(0.8, 1.0)\n",
    "\n",
    "# Training time comparison\n",
    "training_times = [model_results[model]['training_time'] for model in models_list]\n",
    "axes[1].bar(models_list, training_times, alpha=0.8, color='orange')\n",
    "axes[1].set_xlabel('Models')\n",
    "axes[1].set_ylabel('Training Time (seconds)')\n",
    "axes[1].set_title('Training Time Comparison')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select best model based on test accuracy\n",
    "best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['test_accuracy'])\n",
    "best_model = model_results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nüèÜ Best performing model: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {model_results[best_model_name]['test_accuracy']:.4f}\")\n",
    "\n",
    "# Detailed classification report for best model\n",
    "print(f\"\\nüìã Detailed Classification Report for {best_model_name}:\")\n",
    "print(classification_report(y_test_cls, model_results[best_model_name]['y_pred_test'], \n",
    "                          target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935ee87",
   "metadata": {},
   "source": [
    "## 9. Generate Adversarial Password Examples\n",
    "\n",
    "Adversarial training is crucial for making our model robust against passwords that look strong but are actually weak due to predictable transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize adversarial generator\n",
    "adversarial_gen = AdversarialPasswordGenerator()\n",
    "\n",
    "# Generate adversarial examples from weak passwords\n",
    "weak_passwords = [\"password\", \"admin\", \"123456\", \"qwerty\", \"welcome\"]\n",
    "\n",
    "print(\"üé≠ Generating Adversarial Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "adversarial_examples = []\n",
    "for weak_pwd in weak_passwords:\n",
    "    variants = adversarial_gen.generate_multiple_adversarials(weak_pwd, n_variants=3)\n",
    "    \n",
    "    print(f\"\\nBase password: '{weak_pwd}'\")\n",
    "    print(\"Adversarial variants:\")\n",
    "    \n",
    "    for i, variant in enumerate(variants, 1):\n",
    "        print(f\"  {i}. {variant}\")\n",
    "        adversarial_examples.append(variant)\n",
    "\n",
    "# Test how our current model handles these adversarial examples\n",
    "print(f\"\\nüß™ Testing Model Robustness Against Adversarial Examples:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "adversarial_results = []\n",
    "for password in adversarial_examples[:10]:  # Test first 10\n",
    "    # Extract features\n",
    "    features = feature_extractor.extract_features(password)\n",
    "    features_df_single = pd.DataFrame([features])\n",
    "    \n",
    "    # Ensure same feature order as training\n",
    "    features_df_single = features_df_single.reindex(columns=X.columns, fill_value=0)\n",
    "    \n",
    "    # Predict with best model\n",
    "    prediction = best_model.predict(features_df_single)[0]\n",
    "    probabilities = best_model.predict_proba(features_df_single)[0]\n",
    "    predicted_strength = label_encoder.inverse_transform([prediction])[0]\n",
    "    \n",
    "    adversarial_results.append({\n",
    "        'Password': password,\n",
    "        'Predicted_Strength': predicted_strength,\n",
    "        'Confidence': max(probabilities),\n",
    "        'Weak_Prob': probabilities[0],\n",
    "        'Medium_Prob': probabilities[1],\n",
    "        'Strong_Prob': probabilities[2]\n",
    "    })\n",
    "    \n",
    "    print(f\"{password:<20} -> {predicted_strength:<8} (confidence: {max(probabilities):.3f})\")\n",
    "\n",
    "# Analyze results\n",
    "adversarial_df = pd.DataFrame(adversarial_results)\n",
    "print(f\"\\nüìä Adversarial Testing Results:\")\n",
    "print(f\"Passwords predicted as Weak: {(adversarial_df['Predicted_Strength'] == 'Weak').sum()}\")\n",
    "print(f\"Passwords predicted as Medium: {(adversarial_df['Predicted_Strength'] == 'Medium').sum()}\")\n",
    "print(f\"Passwords predicted as Strong: {(adversarial_df['Predicted_Strength'] == 'Strong').sum()}\")\n",
    "\n",
    "# The model should ideally classify most of these as Weak since they're based on weak passwords\n",
    "robustness_score = (adversarial_df['Predicted_Strength'] == 'Weak').mean()\n",
    "print(f\"Model Robustness Score: {robustness_score:.3f} (higher is better)\")\n",
    "\n",
    "if robustness_score < 0.7:\n",
    "    print(\"‚ö†Ô∏è  Model may be vulnerable to adversarial attacks. Consider adversarial training.\")\n",
    "else:\n",
    "    print(\"‚úÖ Model shows good robustness against adversarial examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a5071",
   "metadata": {},
   "source": [
    "## 13. Password Strength Prediction Function\n",
    "\n",
    "Let's create a comprehensive function that analyzes any password and provides detailed feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71a0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_password_comprehensive(password, model=best_model, \n",
    "                                  feature_extractor=feature_extractor,\n",
    "                                  label_encoder=label_encoder):\n",
    "    \"\"\"\n",
    "    Comprehensive password analysis function\n",
    "    \"\"\"\n",
    "    # Extract features\n",
    "    features = feature_extractor.extract_features(password)\n",
    "    features_df = pd.DataFrame([features])\n",
    "    features_df = features_df.reindex(columns=X.columns, fill_value=0)\n",
    "    \n",
    "    # Predict strength\n",
    "    prediction = model.predict(features_df)[0]\n",
    "    probabilities = model.predict_proba(features_df)[0]\n",
    "    predicted_strength = label_encoder.inverse_transform([prediction])[0]\n",
    "    \n",
    "    # Estimate crack time\n",
    "    data_gen = PasswordDataGenerator()\n",
    "    crack_time_seconds = data_gen.calculate_crack_time(password)\n",
    "    \n",
    "    # Convert crack time to human readable\n",
    "    if crack_time_seconds < 60:\n",
    "        crack_time_str = f\"{crack_time_seconds:.3f} seconds\"\n",
    "    elif crack_time_seconds < 3600:\n",
    "        crack_time_str = f\"{crack_time_seconds/60:.1f} minutes\"\n",
    "    elif crack_time_seconds < 86400:\n",
    "        crack_time_str = f\"{crack_time_seconds/3600:.1f} hours\"\n",
    "    elif crack_time_seconds < 31536000:\n",
    "        crack_time_str = f\"{crack_time_seconds/86400:.1f} days\"\n",
    "    else:\n",
    "        crack_time_str = f\"{crack_time_seconds/31536000:.1f} years\"\n",
    "    \n",
    "    # Analyze weaknesses\n",
    "    weaknesses = []\n",
    "    suggestions = []\n",
    "    \n",
    "    if features['length'] < 8:\n",
    "        weaknesses.append(\"Password is too short\")\n",
    "        suggestions.append(\"Use at least 8-12 characters\")\n",
    "    \n",
    "    if features['entropy'] < 3.0:\n",
    "        weaknesses.append(\"Low entropy (predictable patterns)\")\n",
    "        suggestions.append(\"Use more diverse and random characters\")\n",
    "    \n",
    "    if features['has_keyboard_pattern']:\n",
    "        weaknesses.append(\"Contains keyboard patterns (qwerty, 123456)\")\n",
    "        suggestions.append(\"Avoid sequential keyboard keys\")\n",
    "    \n",
    "    if features['contains_dictionary_word']:\n",
    "        weaknesses.append(\"Contains common dictionary words\")\n",
    "        suggestions.append(\"Avoid common words like 'password', 'admin'\")\n",
    "    \n",
    "    if features['has_common_substitutions']:\n",
    "        weaknesses.append(\"Uses predictable character substitutions\")\n",
    "        suggestions.append(\"Avoid simple substitutions like @ for a\")\n",
    "    \n",
    "    if features['contains_year']:\n",
    "        weaknesses.append(\"Contains years or dates\")\n",
    "        suggestions.append(\"Avoid birth years or current dates\")\n",
    "    \n",
    "    if features['uppercase_count'] == 0:\n",
    "        suggestions.append(\"Add uppercase letters\")\n",
    "    \n",
    "    if features['digit_count'] == 0:\n",
    "        suggestions.append(\"Add numbers\")\n",
    "    \n",
    "    if features['symbol_count'] == 0:\n",
    "        suggestions.append(\"Add special characters (!@#$%)\")\n",
    "    \n",
    "    return {\n",
    "        'password': password,\n",
    "        'predicted_strength': predicted_strength,\n",
    "        'confidence': max(probabilities),\n",
    "        'probabilities': {\n",
    "            'Weak': probabilities[0],\n",
    "            'Medium': probabilities[1],\n",
    "            'Strong': probabilities[2]\n",
    "        },\n",
    "        'estimated_crack_time': crack_time_str,\n",
    "        'crack_time_seconds': crack_time_seconds,\n",
    "        'features': features,\n",
    "        'weaknesses': weaknesses,\n",
    "        'suggestions': suggestions\n",
    "    }\n",
    "\n",
    "# Test the function with various passwords\n",
    "test_passwords = [\n",
    "    \"123456\",                    # Very weak\n",
    "    \"password\",                  # Weak dictionary word\n",
    "    \"P@ssw0rd123!\",             # Looks strong but isn't\n",
    "    \"MySecurePassword2024!\",     # Medium with predictable year\n",
    "    \"Tr0ub4dor&3\",              # Classic XKCD reference\n",
    "    \"correct-horse-battery-staple\",  # Strong passphrase\n",
    "    \"9Km#vN$2pL@8xR\"            # Strong random\n",
    "]\n",
    "\n",
    "print(\"üîç Comprehensive Password Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for password in test_passwords:\n",
    "    result = analyze_password_comprehensive(password)\n",
    "    \n",
    "    # Color coding for display\n",
    "    strength_colors = {\n",
    "        'Weak': 'üî¥',\n",
    "        'Medium': 'üü†', \n",
    "        'Strong': 'üü¢'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{strength_colors[result['predicted_strength']]} Password: {password}\")\n",
    "    print(f\"   Strength: {result['predicted_strength']} (confidence: {result['confidence']:.3f})\")\n",
    "    print(f\"   Estimated crack time: {result['estimated_crack_time']}\")\n",
    "    \n",
    "    if result['weaknesses']:\n",
    "        print(f\"   ‚ö†Ô∏è  Weaknesses: {', '.join(result['weaknesses'][:2])}\")\n",
    "    \n",
    "    if result['suggestions']:\n",
    "        print(f\"   üí° Suggestions: {', '.join(result['suggestions'][:2])}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Password analysis function created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5914535f",
   "metadata": {},
   "source": [
    "## 15. Interactive Password Testing\n",
    "\n",
    "Now you can test your own passwords! The input will be hidden for security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f26b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive password testing\n",
    "def interactive_password_test():\n",
    "    \"\"\"\n",
    "    Interactive function to test user passwords\n",
    "    \"\"\"\n",
    "    print(\"üîê Interactive Password Strength Analyzer\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Enter a password to analyze (input will be hidden)\")\n",
    "    print(\"Type 'quit' to exit\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # Get password securely (hidden input)\n",
    "            user_password = getpass(\"Enter password: \")\n",
    "            \n",
    "            if user_password.lower() == 'quit':\n",
    "                print(\"üëã Thanks for using the password analyzer!\")\n",
    "                break\n",
    "            \n",
    "            if not user_password:\n",
    "                print(\"‚ùå Please enter a password\")\n",
    "                continue\n",
    "            \n",
    "            # Analyze the password\n",
    "            result = analyze_password_comprehensive(user_password)\n",
    "            \n",
    "            # Display results with formatting\n",
    "            strength_emojis = {\n",
    "                'Weak': 'üî¥',\n",
    "                'Medium': 'üü†',\n",
    "                'Strong': 'üü¢'\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{strength_emojis[result['predicted_strength']]} Analysis Results:\")\n",
    "            print(f\"   Strength: {result['predicted_strength']}\")\n",
    "            print(f\"   Confidence: {result['confidence']:.1%}\")\n",
    "            print(f\"   Estimated crack time: {result['estimated_crack_time']}\")\n",
    "            \n",
    "            # Show probability breakdown\n",
    "            print(f\"\\nüìä Probability Breakdown:\")\n",
    "            for strength, prob in result['probabilities'].items():\n",
    "                print(f\"   {strength}: {prob:.1%}\")\n",
    "            \n",
    "            # Show weaknesses if any\n",
    "            if result['weaknesses']:\n",
    "                print(f\"\\n‚ö†Ô∏è  Identified Weaknesses:\")\n",
    "                for weakness in result['weaknesses']:\n",
    "                    print(f\"   ‚Ä¢ {weakness}\")\n",
    "            \n",
    "            # Show suggestions if any\n",
    "            if result['suggestions']:\n",
    "                print(f\"\\nüí° Improvement Suggestions:\")\n",
    "                for suggestion in result['suggestions']:\n",
    "                    print(f\"   ‚Ä¢ {suggestion}\")\n",
    "            \n",
    "            print(\"\\n\" + \"-\" * 50)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüëã Thanks for using the password analyzer!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error analyzing password: {e}\")\n",
    "\n",
    "# Alternative: Test with predefined examples if getpass doesn't work in notebook\n",
    "def test_example_passwords():\n",
    "    \"\"\"\n",
    "    Alternative testing function with predefined examples\n",
    "    \"\"\"\n",
    "    examples = [\n",
    "        (\"123456\", \"Very common weak password\"),\n",
    "        (\"P@ssw0rd123!\", \"Looks strong but based on 'Password'\"),\n",
    "        (\"MyDog2024!\", \"Personal info + year\"),\n",
    "        (\"7$kL9#mN2@pQ5\", \"Truly random strong password\"),\n",
    "        (\"correct-horse-battery-staple\", \"Strong passphrase\")\n",
    "    ]\n",
    "    \n",
    "    print(\"üîê Testing Example Passwords:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for password, description in examples:\n",
    "        print(f\"\\nüìù {description}\")\n",
    "        result = analyze_password_comprehensive(password)\n",
    "        \n",
    "        strength_emojis = {\n",
    "            'Weak': 'üî¥',\n",
    "            'Medium': 'üü†',\n",
    "            'Strong': 'üü¢'\n",
    "        }\n",
    "        \n",
    "        print(f\"{strength_emojis[result['predicted_strength']]} Password: {password}\")\n",
    "        print(f\"   Strength: {result['predicted_strength']} ({result['confidence']:.1%} confidence)\")\n",
    "        print(f\"   Crack time: {result['estimated_crack_time']}\")\n",
    "        \n",
    "        if result['weaknesses']:\n",
    "            print(f\"   Issues: {', '.join(result['weaknesses'][:2])}\")\n",
    "\n",
    "# Run the example testing\n",
    "test_example_passwords()\n",
    "\n",
    "print(f\"\\nüéâ Congratulations! You've built a complete password strength analyzer!\")\n",
    "print(f\"Key achievements:\")\n",
    "print(f\"‚úÖ Feature engineering for password analysis\")\n",
    "print(f\"‚úÖ Machine learning model training and evaluation\") \n",
    "print(f\"‚úÖ Adversarial robustness testing\")\n",
    "print(f\"‚úÖ Comprehensive password analysis system\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"‚Ä¢ Deploy as a web application using Streamlit\")\n",
    "print(f\"‚Ä¢ Integrate into existing applications via API\")\n",
    "print(f\"‚Ä¢ Collect real password data for improved training\")\n",
    "print(f\"‚Ä¢ Implement additional adversarial training techniques\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
